{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from dataFunc import tokens_str_to_list, tensor_save, tensor_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将数据tokens转化为张量\n",
    "def tokens_str_to_list(tokens):\n",
    "#字符串转列表  \n",
    "    if tokens is None:\n",
    "        print('Tokens have nothing!')\n",
    "        return None\n",
    "    else:\n",
    "        #print(type(tokens.iloc[0][0].replace('[','').replace(']', '').split(', ')))\n",
    "        res = np.array(tokens.iloc[0][0].replace('[','').replace(']', '').split(', '))\n",
    "        \n",
    "    for i in range(len(tokens)-1):\n",
    "        temp = tokens.iloc[i+1][0].replace('[','').replace(']', '').split(', ')\n",
    "        res = np.vstack((res,np.array(temp)))\n",
    "        \n",
    "    #转换数据类型\n",
    "    res = res.astype(np.uint8)\n",
    "    res = torch.from_numpy(res)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#上面的转换太慢，因此将张量保存一下方便读取\n",
    "#此外，暂时不会直接保存tensor，所以用numpy过渡了一下\n",
    "\n",
    "#保存\n",
    "def tensor_save(tensor,path):\n",
    "    save_np = tensor.cpu().numpy()\n",
    "    np.save(path, save_np)\n",
    "\n",
    "#加载\n",
    "def tensor_load(path):\n",
    "    load_np = np.load(path)\n",
    "    tensor = torch.from_numpy(load_np)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练数据\n",
    "\n",
    "#只需第一次运行， 后续保存后可用函数直接调用\n",
    "#读取训练数据\n",
    "train_x_tokens = pd.read_csv('./dataset/train_x_tokens.csv')\n",
    "#训练数据转张量\n",
    "train_X = tokens_str_to_list(train_x_tokens)\n",
    "\n",
    "train_y = pd.read_csv('./dataset/train_y.csv')\n",
    "#label转张量\n",
    "train_y = torch.tensor(train_y.iloc[:,0]).reshape(len(train_y), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_save(train_X, './dataset/train_X.npy')\n",
    "tensor_save(train_y, './dataset/train_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#验证数据\n",
    "\n",
    "#只需第一次运行， 后续保存后可用函数直接调用\n",
    "#读取训练数据\n",
    "valid_x_tokens = pd.read_csv('./dataset/valid_x_tokens.csv')\n",
    "#训练数据转张量\n",
    "valid_X = tokens_str_to_list(valid_x_tokens)\n",
    "\n",
    "valid_y = pd.read_csv('./dataset/valid_y.csv')\n",
    "#label转张量\n",
    "valid_y = torch.tensor(valid_y.iloc[:,0]).reshape(len(valid_y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_save(valid_X, './dataset/valid_X.npy')\n",
    "tensor_save(valid_y, './dataset/valid_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试数据\n",
    "\n",
    "#只需第一次运行， 后续保存后可用函数直接调用\n",
    "#读取训练数据\n",
    "test_x_tokens = pd.read_csv('./dataset/test_x_tokens.csv')\n",
    "#训练数据转张量\n",
    "test_X = tokens_str_to_list(test_x_tokens)\n",
    "\n",
    "test_y = pd.read_csv('./dataset/test_y.csv')\n",
    "#label转张量\n",
    "test_y = torch.tensor(test_y.iloc[:,0]).reshape(len(test_y), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_save(test_X, './dataset/test_X.npy')\n",
    "tensor_save(test_y, './dataset/test_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存词典\n",
    "with open('./dataset/vocab.txt', 'r', encoding = 'utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        vocab_dict[line.replace('\\n', '')] = count\n",
    "        count += 1\n",
    "\n",
    "with open('./dataset/vocab_dict.json', 'w', encoding = 'utf-8') as f2:\n",
    "    json.dump(vocab_dict, f2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
